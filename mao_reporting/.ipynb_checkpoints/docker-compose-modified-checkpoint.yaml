# Modified docker-compose file for Windows with SQLite database

x-airflow-common:
  &airflow-common
  # Use Python base image and install Airflow
  image: python:3.9-slim
  environment:
    &airflow-common-env
    # Using SQLite database with properly formatted path for container
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: sqlite:////airflow/airflow.db
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    # Email configuration
    AIRFLOW__SMTP__SMTP_HOST: ${SMTP_HOST:-smtp.gmail.com}
    AIRFLOW__SMTP__SMTP_PORT: ${SMTP_PORT:-587}
    AIRFLOW__SMTP__SMTP_USER: ${SMTP_USER:-your-email@gmail.com}
    AIRFLOW__SMTP__SMTP_PASSWORD: ${SMTP_PASSWORD:-your-password}
    AIRFLOW__SMTP__SMTP_MAIL_FROM: ${SMTP_MAIL_FROM:-your-email@gmail.com}
    AIRFLOW__SMTP__SMTP_STARTTLS: 'True'
    AIRFLOW__SMTP__SMTP_SSL: 'False'
    # API connection
    ORDER_API_BASE_URL: ${ORDER_API_BASE_URL:-https://api.example.com}
    ORDER_API_CLIENT_ID: ${ORDER_API_CLIENT_ID:-default_client_id}
    ORDER_API_CLIENT_SECRET: ${ORDER_API_CLIENT_SECRET:-default_client_secret}
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./config:/opt/airflow/config
    - ./plugins:/opt/airflow/plugins
    - ./utils:/opt/airflow/utils
    - ./tmp:/tmp
    # Mount your actual Windows Airflow database directory to container
    - C:/Users/mcgui/airflow:/airflow
  entrypoint: >
    /bin/bash -c "
      # Install Python dependencies
      pip install apache-airflow==2.10.0 pandas matplotlib reportlab requests

      # Create necessary directories
      mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins /opt/airflow/config /opt/airflow/utils /tmp
      
      # Make sure the SQLite directory exists
      mkdir -p /airflow
      
      # Initialize Airflow database (if it doesn't exist)
      airflow db init
      
      # Create admin user (will be skipped if already exists)
      airflow users create -r Admin -u admin -p admin -e admin@example.com -f Admin -l User || true
      
      # Start Airflow services
      airflow webserver & airflow scheduler
    "

services:
  # We don't need PostgreSQL since we're using SQLite
  airflow:
    <<: *airflow-common
    ports:
      - "8080:8080"
    restart: always

# We don't need volumes for PostgreSQL